{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf137f3c",
   "metadata": {},
   "source": [
    "#### CIFAR Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananya/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(X_train,Y_train),(X_test,Y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "class_names = ['airplane','car','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db759d69",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76f7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 1)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# getting shape of the dataset \n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d30263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananya/Library/Python/3.9/lib/python/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3749 - loss: 1.7224 - val_accuracy: 0.5751 - val_loss: 1.2201\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5966 - loss: 1.1472 - val_accuracy: 0.6365 - val_loss: 1.0468\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.9968 - val_accuracy: 0.6564 - val_loss: 0.9959\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6842 - loss: 0.9043 - val_accuracy: 0.6617 - val_loss: 0.9729\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7120 - loss: 0.8323 - val_accuracy: 0.6736 - val_loss: 0.9461\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7294 - loss: 0.7894 - val_accuracy: 0.6854 - val_loss: 0.9211\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7460 - loss: 0.7329 - val_accuracy: 0.6875 - val_loss: 0.9209\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7582 - loss: 0.6960 - val_accuracy: 0.6911 - val_loss: 0.9125\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7773 - loss: 0.6497 - val_accuracy: 0.6970 - val_loss: 0.9193\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7940 - loss: 0.5981 - val_accuracy: 0.6931 - val_loss: 0.9659\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.6931 - loss: 0.9659\n",
      "\n",
      "Test accuracy: 0.6930999755859375\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(32, 32, 3)),  # Keep images 32x32x3\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346dce3",
   "metadata": {},
   "source": [
    "#### Building symbolic knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58a8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_facts = {\n",
    "    'airplane': {'vehicle', 'can fly'},\n",
    "    'car': {'vehicle', 'road'},\n",
    "    'truck': {'vehicle', 'road', 'cargo'},\n",
    "    'ship': {'vehicle', 'water'},\n",
    "    'bird': {'animal', 'can fly'},\n",
    "    'cat': {'animal', 'pet'},\n",
    "    'dog': {'animal', 'pet'},\n",
    "    'horse': {'animal', 'farm'},\n",
    "    'deer': {'animal', 'forest'},\n",
    "    'frog': {'animal', 'amphibian', 'forest'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b573a6",
   "metadata": {},
   "source": [
    "#### Composing reasoning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481bcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_property(obj, property):\n",
    "    return property in object_facts.get(obj, set())\n",
    "\n",
    "def explain_property(obj, property):\n",
    "    if has_property(obj, property):\n",
    "        return f\"Yes, a {obj} is a {property}.\"\n",
    "    else:\n",
    "        return f\"No, a {obj} is not a {property}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b31b3e",
   "metadata": {},
   "source": [
    "#### Integrate both perception and reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27bf4f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Neural Network Prediction: cat\n",
      " Ground Truth: cat\n",
      "No, a cat is not a vehicle.\n",
      "No, a cat is not a can fly.\n",
      "Yes, a cat is a pet.\n",
      "No, a cat is not a road.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_index = 0  # Index of the image to explain\n",
    "img = np.expand_dims(X_test[img_index], axis=0)  # Add batch dimension\n",
    "predictions = model.predict(img)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "print(f\"Neural Network Prediction: {predicted_class_name}\\n Ground Truth: {class_names[Y_test[img_index][0]]}\")\n",
    "\n",
    "for property in ['vehicle', 'can fly', 'pet', 'road']:\n",
    "    print(explain_property(predicted_class_name, property))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9484994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
